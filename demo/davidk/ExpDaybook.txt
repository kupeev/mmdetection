June13.2022

    WTD
        zapisat review: what was done tha lest week

            [0a] restring running net
            [0b] settng pars in conf
            [1] display run of teacher model at test set
                global_vars.pars.N1 = 0
                stand:
                    result = inference_detector(model, img)
                    show_result_pyplot(model, img, result)
                our
                    feat_N1 = self.teacher_model.extract_feat(img)
                    results_list_N1 = self.teacher_model.bbox_head.simple_test(feat_N1, img_metas, rescale=rescale)
                        //!uses _get_bboxes_single of gfl_head uses cfg.score_thr



                    bbox_results_N1 = [
                        bbox2result(det_bboxes, det_labels, self.teacher_model.bbox_head.num_classes)
                        for det_bboxes, det_labels in results_list_N1
                    ]
                    show_result_pyplot(self.teacher_model, img_metas[0]['filename'], bbox_results_N1[0],\
            [2] display learned detector at at test set
                global_vars.pars.N2

        zapisat formingcgfpars
        ensure chto shows bolshe
        difduf examples: samomu i ask B
        impl next itwems


June12.2022
    model = build_detector(
        cfg.model,
        train_cfg=cfg.get('train_cfg'),
        test_cfg=cfg.get('test_cfg'))
    model.init_weights()


        __init__, single_stage.py:46
        def build_from_cfg(cfg, registry, default_args=None):

            bbox_head.update(test_cfg=test_cfg)
            self.test_cfg = test_cfg

    ===============
    cfg.score_thr=1e-04
    ===
    test_cfg=dict(
        nms_pre=1000,
        min_bbox_size=0,
        score_thr=0.05,
        nms=dict(type='nms', iou_threshold=0.6),
        max_per_img=100))

    ===
    _get_bboxes_single, gfl_head.py:427
    =============================
    get_bboxes, base_dense_head.py:73
    ================
            outs = self.forward(feats)
            !+0

            results_list = self.get_bboxes(
                *outs, img_metas=img_metas, rescale=rescale)

    ================
    simple_test_bboxes, dense_test_mixins.py:37
    ==================
    simple_test, base_dense_head.py:360
    =============================
    forward_single, gfl_head.py:204

    --------------
    simple_test_bboxes, dense_test_mixins.py:37
    outs = self.forward(feats)

    OKO est outs


June09.2022

    ls -R -l -t | grep '.py' | grep Jun

    ---
    line 52 in optimizer.py
    def after_train_iter(self, runner):
        runner.optimizer.zero_grad()
    ---
    before hook=<mmcv.runner.hooks.optimizer.OptimizerHook object at 0x7fcb5a433f40> torch.sum(self.model.module.bbox_head.gfl_reg.weight.flatten())=tensor(3.0700, device='cuda:0', grad_fn=<SumBackward0>)
    after hook=<mmcv.runner.hooks.optimizer.OptimizerHook object at 0x7fcb5a433f40> torch.sum(self.model.module.bbox_head.gfl_reg.weight.flatten())=tensor(3.0699, device='cuda:0', grad_fn=<SumBackward0>)
    ---
    def call_hook(self, fn_name)
    ---
    after_train_iter, base.py:144
    runner.log_buffer.average(self.interval)


June08.2022

    build_dataloader, builder.py:184
    -----------
    self.interval
    -----------
    losses:
    def average(self, n=0):
    -------------
    hook enum

        for hook in self._hooks:
            getattr(hook, fn_name)(self)

    --------------

    after_train_iter, base.py:144
    runner.log_buffer.average(self.interval)

    after_train_iter, optimizer.py:53
        call_hook, base_runner.py:309
        train, epoch_based_runner.py:54
        run, epoch_based_runner.py:133
        train_detector, train.py:208
        main, train.py:247
        <module>, train.py:256

    -----------------

    epoch_based_runner.py
    self.call_hook('after_train_epoch')
    data_batch['img_metas'].data[0][0]['filename']


        /home/konstak/projects2/mmdetection/venv_mmdet/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py
        epoch_runner(data_loaders[i], **kwargs) //epoch_based_runner.py line 172

            def train(self, data_loader, **kwargs): //epoch_based_runner.py line 40
                //run epoch
                for i, data_batch in enumerate(self.data_loader):
                    self._inner_iter = i
                    self.call_hook('before_train_iter') //ie before batch
                    self.run_iter(data_batch, train_mode=True, **kwargs)


                    run_iter, epoch_based_runner.py:29 outputs = self.model.train_step(data_batch, self.optimizer,
                    //ru  at one batch

                        train_step, base.py:255 losses = self(**data)
                            forward_train, kd_one_stage.py:100
                        train_step, base.py:261 return outputs
        ============

        self.call_hook('after_train_epoch')

            def _save_checkpoint(self, runner):
                """Save the current checkpoint and delete unwanted checkpoint."""
                runner.save_checkpoint(


        self._epoch += 1

June07.2022

    TBD

        [] filling the weights

            (A)

                model = build_detector(
                model.init_weights()
                     checkpoint = _load_checkpoint(filename, map_location, logger)
                        filename = 'torchvision://resnet50'

            (B)
                the network is loaded at:
                    runner.load_checkpoint(cfg.load_from)

        [] where saved:
            save_checkpoint() in epoch_based_runner
                    'epoch_3.pth'


                    self.model.module.backbone.layer1[0].conv1.weight.shape Out[46]: torch.Size([64, 64, 1, 1])
                    self.model.module.backbone.layer1[0].conv1.weight.flatten()[0:5]  Out[47]: tensor([ 0.0035,  0.0399, -0.0248, -0.0278,  0.0889], device='cuda:0')

                    self.model.module.neck.lateral_convs[0].conv.weight.shape Out[29]: torch.Size([256, 512, 1, 1])
                    self.model.module.neck.lateral_convs[0].conv.weight.flatten()[0:5] tensor([ 0.0608,  0.0453, -0.0212,  0.0852, -0.0361], device='cuda:0',

                    //runner.model.module.backbone.layer1[0].conv1.weight.shape
                    self.model.module.bbox_head.gfl_cls.weight.shape                                Out[5]: torch.Size([5, 256, 3, 3])
                    self.model.module.bbox_head.gfl_cls.weight.flatten(0)[0:5]                      Out[6]:tensor([ 0.0065, -0.0121, -0.0164,  0.0052,  0.0083], device='cuda:0',
                    self.model.module.bbox_head.gfl_reg.weight.shape                                Out[7]: torch.Size([68, 256, 3, 3])
xx                  self.model.module.bbox_head.gfl_reg.weight.flatten()[0:5]                       Out[8]:tensor([-0.0018,  0.0032, -0.0028,  0.0092,  0.0087], device='cuda:0',
                    self.model.module.bbox_head.bbox_head_student.gfl_cls.weight.shape              Out[9]: torch.Size([80, 256, 3, 3])
                    self.model.module.bbox_head.bbox_head_student.gfl_cls.weight.flatten()[0:5] tensor([-0.0104, -0.0147,  0.0025, -0.0020,  0.0045], device='cuda:0',
                    self.model.module.bbox_head.bbox_head_student.gfl_reg.weight.shape Out[11]: torch.Size([68, 256, 3, 3])
x?                  self.model.module.bbox_head.bbox_head_student.gfl_reg.weight.flatten()[0:5] tensor([-0.0035, -0.0039, -0.0065, -0.0014,  0.0036], device='cuda:0',




        QQ1
            cfg['load_from'] = None where from
        QQ2
            Pretrained: should affet the backbone. Where?

        where the model is saved
            /home/konstak/projects2/mmdetection/work_dirs/config_ld_double/epoch_200.pth

        where the model is loaded
            we know just
                teacher_ckpt = 'https://download.openmmlab.com/mmdetection/v2.0/gfl/gfl_r101_fpn_mstrain_2x_coco/gfl_r101_fpn_mstrain_2x_coco_20200629_200126-dd12f847.pth'  # noqa

            __init__, single_stage.py:42


        start train model ensure loss yored
        why not display:
            comp M1

June06.2022

    def train_step(self, data, optimizer):
        """The iteration step during training.

        This method defines an iteration step during training, except for the
        back propagation and optimizer updating, which are done in an optimizer
        hook.
    =============
    remo:
        teacher model is built
            self.teacher_model = build_detector(teacher_config['model']) #qq teacher

    ============

    from mmdet.core import get_classes
    model.CLASSES = get_classes('coco')


    dataset = DATASETS.get(cfg.data.test['type'])
    assert (dataset is not None)
    model.CLASSES = dataset.CLASSES

    self.CLASSES = self.get_classes(classes)

    a u nas:
    self.teacher_model.CLASSES = get_classes('coco')



June01.2022

    load_from = None



May31.2022

    =================
    ma ze:
    if self.__class__.__name__ == 'LDHeadDouble':

May30.2022


    single_stage.py: def simple_test(self, img, img_metas, rescale=False):
        feat = self.extract_feat(img)
    =================================
    forward_test in base.py

    =================================
    # qq5
    pos_decode_bbox_pred = self.bbox_coder.decode(
        pos_anchor_centers, pos_bbox_pred_corners)
    pos_decode_bbox_targets = pos_bbox_targets / stride[0]

May29.2022

    assign, atss_assigner.py:67

    inside_flags = anchor_inside_flags(flat_anchors, valid_flags,
                                       img_meta['img_shape'][:2],
                                       self.train_cfg.allowed_border)


    len(np.argwhere((assign_result.labels!=-1).cpu().detach().numpy()))

May26.2022

    ISSUE2
        does not work
            os.getcwd()
            Out[7]: '/home/konstak/projects2/mmdetection/demo/davidk'
            teacher_config
            Out[8]: 'configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py'

        ------------
        works
            os.getcwd()
            Out[3]: '/home/konstak/projects2/mmdetection'
            import sys; print('Python %s on %s' % (sys.version, sys.platform))
            Python 3.8.10 (default, Mar 15 2022, 12:22:08)
            [GCC 9.4.0] on linux
            teacher_config
            Out[5]: 'configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py'


        solut:
        configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py ->  /home/konstak/projects2/mmdetection/configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py

    ISSUE1

        https://mmdetection.readthedocs.io/en/latest/1_exist_data_model.html
        https://mmdetection.readthedocs.io/en/latest/1_exist_data_model.html#
            A notebook demo can be found in demo/inference_demo.ipynb.


        jupyter notebook

        test_ld_double.ipynb

        ../work_dirs/config_ld_double/_config_ld_double.py



        FileNotFoundError: file "/home/konstak/projects2/mmdetection/demo/configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py" does not exist

May25.2022
    self.loss_weight ??

        kd_one_stage
        line 94

            self.call_hook('after_train_iter')
            #561

                and self.reducer._rebuild_buckets()):
                line 42
                !SECOND IT

    probezat zachodim po odnomu razu
        why so many times
            knowledge_distillation_kl_div_loss
    ==================

    self.teacher_model = build_detector(teacher_config['model']) #qq teacher

    'configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py'

    https://download.openmmlab.com/mmdetection/v2.0/gfl/gfl_r101_fpn_mstrain_2x_coco/gfl_r101_fpn_mstrain_2x_coco_20200629_200126-dd12f847.pth

    gfl_r101_fpn_mstrain_2x_coco_20200629_200126

    gfl_r101_fpn_mstrain_2x_coco_20200629_200126

    load_checkpoint(
    self.teacher_model, teacher_ckpt, map_location='cpu')


        model.init_weights()
        train.py


    ==================
    load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/gfl/gfl_r101_fpn_mstrain_2x_coco/gfl_r101_fpn_mstrain_2x_coco_20200629_200126-dd12f847.pth
    2022-05-25 15:38:10,979 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
    2022-05-25 15:38:10,979 - mmcv - INFO - load model from: torchvision://resnet50
    2022-05-25 15:38:10,979 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50
    2022-05-25 15:38:11,019 - mmcv - WARNING - The model and loaded state dict do not match exactly

            BUT THE SAME FOR lunch_ld !

            unexpected key in source state_dict: fc.weight, fc.bias
                initialize(self, self.init_cfg)


                    _initialize(module, cp_cfg) in
                        weight_init.py
                            /home/konstak/projects2/mmdetection/venv_mmdet/lib/python3.8/site-packages/mmcv/cnn/utils

                                    load_state_dict(model, state_dict, strict, logger)

                                        /home/konstak/projects2/mmdetection/venv_mmdet/lib/python3.8/site-packages/mmcv/runner
                                        checkpoint.py
                                        The model and loaded state dict do not match exactly

                                            err_msg
                                            Out[3]: ['unexpected key in source state_dict: fc.weight, fc.bias\n']

                                                !
                                                module._load_from_state_dict(state_dict, prefix, local_metadata, True,
                                                in
                                                checkpoint.py

    ====================================
    2022-05-25 15:00:47,248 - mmdet - INFO - Exp name: config_ld_double.py
    2022-05-25 15:00:47,248 - mmdet - INFO - Epoch(val) [2][59]	bbox_mAP: 0.0230, bbox_mAP_50: 0.0780, bbox_mAP_75: 0.0030, bbox_mAP_s: 0.3000, bbox_mAP_m: 0.0810, bbox_mAP_l: 0.0300, bbox_mAP_copypaste: 0.023 0.078 0.003 0.300 0.081 0.030
    DONE (t=0.08s).
    ------------sums------------
    tensor(-8.4382, device='cuda:0', grad_fn=<SumBackward0>) CLS: NO_CHANGED
    tensor(-6.1300, device='cuda:0', grad_fn=<SumBackward0>) REG: CHANGED
    tensor(-0.2313, device='cuda:0', grad_fn=<SumBackward0>) CLS: NO_CHANGED
    tensor(-0.7778, device='cuda:0', grad_fn=<SumBackward0>) REG: CHANGED
    ------------sums2------------
    tensor(7.5946, device='cuda:0', grad_fn=<SumBackward0>)
    tensor(-2.3181, device='cuda:0', grad_fn=<SumBackward0>)
    tensor(1.7751, device='cuda:0', grad_fn=<SumBackward0>)
    tensor(3.0841, device='cuda:0', grad_fn=<SumBackward0>)
    ........
    2022-05-25 15:01:15,531 - mmdet - INFO - Epoch(val) [3][59]	bbox_mAP: 0.0120, bbox_mAP_50: 0.0400, bbox_mAP_75: 0.0000, bbox_mAP_s: 0.0500, bbox_mAP_m: 0.1010, bbox_mAP_l: 0.0120, bbox_mAP_copypaste: 0.012 0.040 0.000 0.050 0.101 0.012
    ------------sums------------
    tensor(-8.4382, device='cuda:0', grad_fn=<SumBackward0>) CLS: NO_CHANGED
    tensor(-5.3038, device='cuda:0', grad_fn=<SumBackward0>) REG: CHANGED
    tensor(-0.2313, device='cuda:0', grad_fn=<SumBackward0>) CLS: NO_CHANGED
    tensor(-0.7776, device='cuda:0', grad_fn=<SumBackward0>) REG: CHANGED
    ------------sums2------------
    tensor(7.2155, device='cuda:0', grad_fn=<SumBackward0>)
    tensor(-0.6361, device='cuda:0', grad_fn=<SumBackward0>)
    tensor(0.5656, device='cuda:0', grad_fn=<SumBackward0>)
    tensor(3.0836, device='cuda:0', grad_fn=<SumBackward0>)



May24.2022
    ONI DELAYT NADZIRANIE NAD TEMI KOTORUE PROWLI 5
    MY DOLZNU NADZIRANIE NAD TEMI KOTORUE PROWLI 80

    SEEMS RIGHT:
    INDEED, IF FILTER, THEN NADZIRANIE NAD TEM CHTO REACHER PROSHEL


May23.2022

    RuntimeError: Expected to have finished reduction in the prior iteration before
    starting a new one. This error indicates that your module has
    parameters that were not used in producing loss.
    You can enable unused parameter detection by passing the
    keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`,
    and by making sure all `forward` function outputs participate in calculating loss.


    git commit -a -m "May18.2022: PyTorch-Autoencoder.ipynb"

    self.teacher_model = build_detector(teacher_config['model'])


    self.bbox_head.bbox_head_student = build_head(bbox_head)


    self.teacher_model = build_detector(teacher_config['model']) #qq1

    cfg['find_unused_parameters'] = True

    self.contains_bbox_head_student = 1

    {'type': 'LDHeadDouble', 'num_classes': 5, 'in_channels': 256, 'stacked_convs': 4,
    'feat_channels': 256,
    'anchor_generator': {'type': 'AnchorGenerator', 'ratios': [1.0], 'octave_base_scale': 8, 'scales_per_octave': 1, 'strides': [8, 16, 32, 64, 128]}, 'loss_cls': {'type': 'QualityFocalLoss', 'use_sigmoid': True, 'beta': 2.0, 'loss_weight': 1.0}, 'loss_dfl': {'type': 'DistributionFocalLoss', 'loss_weight': 0.25}, 'loss_ld': {'type': 'KnowledgeDistillationKLDivLoss', 'loss_weight': 0.25, 'T': 10}, 'reg_max': 16, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'train_cfg': {'assigner': {'type': 'ATSSAssigner', 'topk': 9}, 'allowed_border': -1, 'pos_weight': -1, 'debug': False}, 'test_cfg': {'nms_pre': 1000, 'min_bbox_size': 0, 'score_thr': 0.05, 'nms': {'type': 'nms', 'iou_threshold': 0.6}, 'max_per_img': 100}}


    if self.contains_bbox_head_student = 1

    self.bbox_head = build_head(bbox_head)


    important place in kd_one_stage

            x = self.extract_feat(img)
            with torch.no_grad():
                teacher_x = self.teacher_model.extract_feat(img)
                out_teacher = self.teacher_model.bbox_head(teacher_x)

            losses = self.bbox_head.forward_train(x, out_teacher, img_metas,
                                                  gt_bboxes, gt_labels,
                                                  gt_bboxes_ignore)



    'LDHeadDouble' in str(type(self))

    self.teacher_model = build_detector(teacher_config['model']) #qq teacher

    teacher_config='configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py',

    teacher_config['model']['bbox_head']

    old in single_stage: # qq old


            bbox_head.update(train_cfg=train_cfg)
            bbox_head.update(test_cfg=test_cfg)

    ----------------
    class NumClassCheckHook(Hook):
    assert module.num_classes == len(dataset.CLASSES), \
    GFLHead(


    soft_student = outs_student[1] #outs_student[0][3]: (1,80,3,13) soft_student = outs_student[1][3]: (1,68,3,13)



    2022-05-23 16:21:52,580 - mmcv - WARNING - The model and loaded state dict do not match exactly


Apr26.2022

    REMS

        forward_train, kd_one_stage.py: 72
        losses = self.bbox_head.forward_train(x, out_teacher, img_metas,
                                              gt_bboxes, gt_labels,
                                              gt_bboxes_ignore)


    'forward_train' in dir(self.bbox_head)
    Out[4]: True
    'forward_train' in dir(self.backbone)
    Out[5]: False


    MAIN
        shlita
            svyaz s obsh: till 09:45: obsh
            kakie klasses delayut

        pict:
            chto oni VS chto ya

        tbd:
            moy maslul


        zazubrit:
            ich losses
    AUX
        posmotret ich vesa



    ==========================
    out_teacher = self.teacher_model.bbox_head(teacher_x)
    - - - -
    self.teacher_model = build_detector(teacher_config['model'])
    - - - -

    LDHead(GFLHead(AnchorHead)):

        self():  feat->(classes, softtargets)

    KnowledgeDistillationSingleStageDetector:
        self.teacher_model.bbox_head : teacher feat -> (classes, softtargets)


    cls_scores (list[Tensor]): Cls and quality scores for each scale


    def loss in ld_head.py

    ======================



Apr25.2022

    train_step() base.py //self is BaseDetector
        losses = self(**data)
        =forward() base.py:177:
            return self.forward_train(img, img_metas, **kwargs)
            =forward_train() kd_one_stage.py:67
                x = self.extract_feat(img) //self: KnowledgeDistillationSingleStageDetector
                extract_feat(), single_stage.py:43
                    x = self.backbone(img)

                // eto FCOS feature pyramide  for student
                //x[0].shape torch.Size([1, 256, 100, 100])
                //...
                //x[4].shape torch.Size([1, 256, 7, 7])

                teacher_x = self.teacher_model.extract_feat(img)
                //FCOS feature pyramide  for teacher
                out_teacher = self.teacher_model.bbox_head(teacher_x)
                    out_teacher = {tuple: 2}
                     0 = {list: 5}
                      0 = {Tensor: (1, 80, 100, 100)}
                      1 = {Tensor: (1, 80, 50, 50)}
                      2 = {Tensor: (1, 80, 25, 25)}
                      3 = {Tensor: (1, 80, 13, 13)}
                      4 = {Tensor: (1, 80, 7, 7)}
                     1 = {list: 5}
                      0 = {Tensor: (1, 68, 100, 100)}
                      1 = {Tensor: (1, 68, 50, 50)}
                      2 = {Tensor: (1, 68, 25, 25)}
                      3 = {Tensor: (1, 68, 13, 13)}
                      4 = {Tensor: (1, 68, 7, 7)}
                We: classes and bb distrib-s

                //self is LDHead derived from GFLHead
                losses = self.bbox_head.forward_train
                (x, out_teacher, img_metas,gt_bboxes,gt_labels,gt_bboxes_ignore)

                =forward_train, ld_head.py:171

                    outs = self(x) //x - feat, self: class of LDHead, see obtaining out_teacher above
                    soft_target = out_teacher[1]

                    loss_inputs = outs + (gt_bboxes, gt_labels,soft_target, img_metas)

                    losses = self.loss(*loss_inputs,gt_bboxes_ignore=gt_bboxes_ignore)
                    =loss() in ld_head.py

                        line:221
                        cls_reg_targets = self.get_targets(
                        =get_targets() in gfl.head

                       (anchor_list, labels_list,label_weights_list,bbox_targets_list,
                       bbox_weights_list, num_total_pos,num_total_neg) = cls_reg_targets

                       losses_cls, losses_bbox, losses_dfl, losses_ld, \
                       avg_factor = multi_apply(self.loss_single,anchor_list,cls_scores,
                           bbox_preds,labels_list,label_weights_list,
                           bbox_targets_list,self.prior_generator.strides,
                           soft_target,num_total_samples=...)

                        = loss_single, ld_head.py: 108

                            ld_head.py: 122
                            loss_ld = self.loss_ld(
                            soft_corners // 72 * torch.Size([17])
                            weight_targets[:, None].expand(-1, 4).reshape(-1).shape //torch.Size([72])

                            = def forward() in class KnowledgeDistillationKLDivLoss(nn.Module):

                                loss_kd = self.loss_weight * knowledge_distillation_kl_div_loss(
                                pred, soft_label, weight,

                       return dict(
                            loss_cls=losses_cls,
                            loss_bbox=losses_bbox,
                            loss_dfl=losses_dfl,
                            loss_ld=losses_ld)

---------------
soft_target = out_teacher[1]
key:
multi_apply in ld-head
-------------
train_step, base.py
    losses = self(**data)
        losses.keys()
        Out[3]: dict_keys(['loss_cls', 'loss_bbox', 'loss_dfl', 'loss_ld'])


x = self.backbone(img) in /home/konstak/projects2/mmdetection/mmdet/models/detectors/single_stage.py


    self.backbone(img)[0].shape
        Out[6]: torch.Size([1, 256, 200, 200])
        self.backbone(img)[1].shape
        Out[7]: torch.Size([1, 512, 100, 100])
        self.backbone(img)[2].shape
        Out[8]: torch.Size([1, 1024, 50, 50])
        self.backbone(img)[3].shape
        Out[9]: torch.Size([1, 2048, 25, 25])


        x - urovni backbone


after self.neck

   x[0].shape
    Out[11]: torch.Size([1, 256, 100, 100])
    x[1].shape
    Out[12]: torch.Size([1, 256, 50, 50])
    x[2].shape
    Out[13]: torch.Size([1, 256, 25, 25])
    x[3].shape
    Out[14]: torch.Size([1, 256, 13, 13])
    x[4].shape
    Out[15]: torch.Size([1, 256, 7, 7])


eto feature pyramide  of FCOS

qqq

    --nproc_per_node=1 --master_port=29500 ./tools/train.py configs/michael/davidk/config_ld.py --launcher pytorch
                                                            >>>>configs/michael/davidk/config_ld_double.py<<<<

                _base_ = ['/home/konstak/projects2/mmdetection/configs/ld/ld_r50_gflv1_r101_fpn_coco_1x.py']
                _base_ = ['./ld_r18_gflv1_r101_fpn_coco_1x.py']

                    type='KnowledgeDistillationSingleStageDetector',
                    teacher_config=
                    '/home/konstak/projects2/mmdetection/configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py',
                    teacher_ckpt=
                    'https://download.openmmlab.com/mmdetection/v2.0/gfl/gfl_r101_fpn_mstrain_2x_coco/gfl_r101_fpn_mstrain_2x_coco_20200629_200126-dd12f847.pth',

                    bbox_head=dict(
                        type='LDHead',
        >>>>
                _base_ = ['/home/konstak/projects2/mmdetection/configs/ld/ld_r50_gflv1_r101_fpn_coco_1x_double.py']
                _base_ = ['./ld_r18_gflv1_r101_fpn_coco_1x_double.py']

                    type='KnowledgeDistillationSingleStageDetector',
                    teacher_config=
                    '/home/konstak/projects2/mmdetection/configs/gfl/gfl_r101_fpn_mstrain_2x_coco.py',

                    teacher_ckpt=
                    'https://download.openmmlab.com/mmdetection/v2.0/gfl/gfl_r101_fpn_mstrain_2x_coco/gfl_r101_fpn_mstrain_2x_coco_20200629_200126-dd12f847.pth',

                    bbox_head=dict(
                        LDHeadDouble

    ====

    after

    cfg = Config.fromfile(args.config)
        [1]the cfg['model'] and  cfg.model is the same
        [2] defined is cfg['model']['test_cfg']
            from test_cfg of model in ld_r18_gflv1_r101_fpn_coco_1x.py

    model = build_detector(cfg.model,
        tam v glubine obnovlyaem self.bbox_head = build_head(bbox_head)
        ->
        self.bbox_head.test_cfg['score_thr']



    ====

    saced:
    /home/konstak/projects2/mmdetection/work_dirs/config_ld_double/config_ld_double.py

    ========
    import json; print(json.dumps(cfg, indent = 4))


